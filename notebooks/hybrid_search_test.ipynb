{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede8a5ea",
   "metadata": {},
   "source": [
    "# Hybrid Search Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79461bc1",
   "metadata": {},
   "source": [
    "## openai & prompt ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df1694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import dotenv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai ì„¤ì •\n",
    "\n",
    "# API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # í™˜ê²½ë³€ìˆ˜ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”\n",
    ")\n",
    "\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_object\",\n",
    "    \"json_schema\": {\n",
    "            \"name\": \"translate_result\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\"type\": \"string\"},\n",
    "                    \"translated\": {\"type\": \"string\"},\n",
    "                    \"keyword\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                },\n",
    "                \"required\": [\"text\", \"translated\", \"keyword\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "\n",
    "def chat(\n",
    "    messages: List[Dict[str, str]], \n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    response_format: dict = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    OpenAI GPT-4o-mini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì™„ì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ [{\"role\": \"user\", \"content\": \"ë©”ì‹œì§€\"}]\n",
    "        model: ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’: gpt-4o-mini)\n",
    "        **kwargs: OpenAI API ë§¤ê°œë³€ìˆ˜ë“¤\n",
    "            - temperature: ì°½ì˜ì„± ì¡°ì ˆ (0.0-2.0, ê¸°ë³¸ê°’: 0.7)\n",
    "            - max_tokens: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 1000)\n",
    "            - top_p: í™•ë¥  ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.95)\n",
    "            - frequency_penalty: ë¹ˆë„ í˜ë„í‹° (ê¸°ë³¸ê°’: 0.0)\n",
    "            - presence_penalty: ì¡´ì¬ í˜ë„í‹° (ê¸°ë³¸ê°’: 0.0)\n",
    "            - stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€ (ê¸°ë³¸ê°’: False)\n",
    "            - ê¸°íƒ€ OpenAI APIê°€ ì§€ì›í•˜ëŠ” ëª¨ë“  ë§¤ê°œë³€ìˆ˜\n",
    "        \n",
    "    Returns:\n",
    "        GPT ì‘ë‹µ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "    default_params = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"presence_penalty\": 0.0\n",
    "    }\n",
    "    \n",
    "    # ê¸°ë³¸ê°’ê³¼ ì‚¬ìš©ì ì…ë ¥ ë³‘í•©\n",
    "    params = {**default_params, **kwargs}\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format=response_format,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "import json\n",
    "import os\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²°\n",
    "mongodb_client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "print(\"ğŸ”— MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì™„ë£Œ\")\n",
    "\n",
    "try:\n",
    "    # ì—°ê²° ìƒíƒœ í™•ì¸\n",
    "    mongodb_client.admin.command('ping')\n",
    "    print(\"âœ… MongoDB ì—°ê²° ì„±ê³µ!\")\n",
    "    \n",
    "    # ì„œë²„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    server_info = mongodb_client.server_info()\n",
    "    print(f\"ğŸ“Š MongoDB ë²„ì „: {server_info['version']}\")\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ í™•ì¸\n",
    "    db_list = mongodb_client.list_database_names()\n",
    "    print(f\"ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤: {db_list}\")\n",
    "    \n",
    "    # í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´\n",
    "    current_db = mongodb_client[config['path']['db_name']]\n",
    "    print(f\"ğŸ¯ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤: {config['path']['db_name']}\")\n",
    "    \n",
    "    # ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸\n",
    "    collections = current_db.list_collection_names()\n",
    "    print(f\"ğŸ“‹ ì»¬ë ‰ì…˜ ëª©ë¡: {collections}\")\n",
    "    \n",
    "    # íƒ€ê²Ÿ ì»¬ë ‰ì…˜ í™•ì¸\n",
    "    target_collection = current_db[config['path']['collection_name']]\n",
    "    print(f\"ğŸ¯ íƒ€ê²Ÿ ì»¬ë ‰ì…˜: {config['path']['collection_name']}\")\n",
    "    \n",
    "    # ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´\n",
    "    stats = current_db.command(\"collStats\", config['path']['collection_name'])\n",
    "    print(f\"ğŸ“ˆ ë¬¸ì„œ ê°œìˆ˜: {stats['count']:,}\")\n",
    "    print(f\"ğŸ’¾ ì»¬ë ‰ì…˜ í¬ê¸°: {stats['size']:,} bytes ({stats['size']/1024/1024:.2f} MB)\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë¬¸ì„œ í™•ì¸\n",
    "    sample_doc = target_collection.find_one()\n",
    "    if sample_doc:\n",
    "        print(f\"ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ í‚¤: {list(sample_doc.keys())}\")\n",
    "        print(f\"ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ ID: {sample_doc.get('_id', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì»¬ë ‰ì…˜ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì¸ë±ìŠ¤ ì •ë³´ í™•ì¸\n",
    "    indexes = target_collection.list_indexes()\n",
    "    print(f\"ğŸ” ì¸ë±ìŠ¤ ì •ë³´:\")\n",
    "    for idx in indexes:\n",
    "        print(f\"   - {idx['name']}: {idx['key']}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"âœ… MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print(f\"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "except pymongo.errors.ServerSelectionTimeoutError as e:\n",
    "    print(f\"âŒ ì„œë²„ ì„ íƒ íƒ€ì„ì•„ì›ƒ: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.prompts import load_prompt\n",
    "\n",
    "translate_prompt = load_prompt(\"translate\")\n",
    "print(translate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": translate_prompt},\n",
    "#     {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"}\n",
    "# ]\n",
    "\n",
    "# response = chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a6b03",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_df = pd.read_csv(\"../data/helloworld_test_query.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9719a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° ë° ë°ì´í„°í”„ë ˆì„ ìƒì„±\n",
    "import pandas as pd\n",
    "\n",
    "# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "query_df = pd.read_csv('../data/helloworld_test_query.csv')\n",
    "print(f\"ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ê°œìˆ˜: {len(query_df)}\")\n",
    "print(\"\\në°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼:\")\n",
    "print(query_df.columns.tolist())\n",
    "print(\"\\nì²« 3ê°œ í–‰:\")\n",
    "print(query_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²ˆì—­ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "from prompts.prompts import load_prompt\n",
    "\n",
    "translate_prompt = load_prompt(\"translate\")\n",
    "print(\"ë²ˆì—­ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# ë²ˆì—­ í•¨ìˆ˜ ì •ì˜\n",
    "def translate_query(query_text):\n",
    "    \"\"\"ë²ˆì—­ ì¿¼ë¦¬ë¥¼ GPT-4o-minië¡œ ë²ˆì—­í•˜ì—¬ JSON ì‘ë‹µì„ ë°›ëŠ”ë‹¤\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": translate_prompt},\n",
    "        {\"role\": \"user\", \"content\": query_text}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = chat(messages, temperature=0.1)\n",
    "        result = json.loads(response)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ë²ˆì—­ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee72e0a",
   "metadata": {},
   "source": [
    "## ë²ˆì—­ & í‚¤ì›Œë“œ ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ì¿¼ë¦¬ ì²˜ë¦¬\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "all_results = []\n",
    "translated_results = []\n",
    "keyword_results = []\n",
    "\n",
    "print(f\"ì´ {len(query_df)}ê°œì˜ ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# ê° ì¿¼ë¦¬ ì²˜ë¦¬\n",
    "for idx, row in tqdm(query_df.iterrows(), total=len(query_df), desc=\"ë²ˆì—­ ì§„í–‰\"):\n",
    "    query_text = row['translated_query']\n",
    "    \n",
    "    # ë²ˆì—­ ìˆ˜í–‰\n",
    "    result = translate_query(query_text)\n",
    "    \n",
    "    if result is not None:\n",
    "        # ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # ê°œë³„ í•„ë“œ ì €ì¥\n",
    "        translated_results.append(result.get('translated', ''))\n",
    "        keyword_results.append(result.get('keyword', []))\n",
    "        \n",
    "        print(f\"[{idx+1}/{len(query_df)}] ì™„ë£Œ: {result.get('translated', '')[:50]}...\")\n",
    "    else:\n",
    "        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ê°’ ì¶”ê°€\n",
    "        all_results.append(None)\n",
    "        translated_results.append('')\n",
    "        keyword_results.append([])\n",
    "        print(f\"[{idx+1}/{len(query_df)}] ì˜¤ë¥˜ ë°œìƒ\")\n",
    "    \n",
    "    # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ì ì‹œ ëŒ€ê¸°\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\në²ˆì—­ ì™„ë£Œ! ì´ {len([r for r in all_results if r is not None])}ê°œ ì„±ê³µ\")\n",
    "print(f\"ì˜¤ë¥˜ ë°œìƒ: {len([r for r in all_results if r is None])}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6292628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥\n",
    "import datetime\n",
    "\n",
    "# 1. JSONL íŒŒì¼ë¡œ ì „ì²´ ê²°ê³¼ ì €ì¥\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "jsonl_filename = f\"../data/translation_results_{timestamp}.jsonl\"\n",
    "\n",
    "print(f\"JSONL íŒŒì¼ ì €ì¥: {jsonl_filename}\")\n",
    "\n",
    "with open(jsonl_filename, 'w', encoding='utf-8') as f:\n",
    "    for result in all_results:\n",
    "        if result is not None:\n",
    "            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "        else:\n",
    "            f.write(json.dumps({\"error\": \"translation_failed\"}, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"JSONL íŒŒì¼ ì €ì¥ ì™„ë£Œ: {len(all_results)}ê°œ ë ˆì½”ë“œ\")\n",
    "\n",
    "# 2. ë°ì´í„°í”„ë ˆì„ì— ìƒˆ ì»¬ëŸ¼ ì¶”ê°€\n",
    "query_df['translated_4o_mini'] = translated_results\n",
    "query_df['keyword_4o_mini'] = keyword_results\n",
    "\n",
    "print(\"\\në°ì´í„°í”„ë ˆì„ ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ:\")\n",
    "print(f\"- translated_4o_mini: {len(translated_results)}ê°œ\")\n",
    "print(f\"- keyword_4o_mini: {len(keyword_results)}ê°œ\")\n",
    "\n",
    "# 3. ì—…ë°ì´íŠ¸ëœ CSV ì €ì¥\n",
    "updated_csv_filename = f\"../data/helloworld_test_query_with_translation_{timestamp}.csv\"\n",
    "query_df.to_csv(updated_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nì—…ë°ì´íŠ¸ëœ CSV íŒŒì¼ ì €ì¥: {updated_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[['query', 'translated_4o_mini', 'keyword_4o_mini']]\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05552f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in query_df.iterrows():\n",
    "    print(row['query'])\n",
    "    print(row['translated_4o_mini'])\n",
    "    print(row['keyword_4o_mini'])\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00405b5f",
   "metadata": {},
   "source": [
    "## ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í‰ê°€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import dotenv\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query_df = pd.read_csv(\"../data/helloworld_test_query_with_translation_20250916_192212.csv\")\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a64125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "for i, row in query_df.iterrows():\n",
    "    print(i, len(ast.literal_eval(row['ground_truth_id'])))\n",
    "\n",
    "# ìµœëŒ€ 20ê°œê¹Œì§€ ë°˜í™˜í•´ì•¼ í•¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB ì—°ê²° ë° ëª¨ë¸ ì„¤ì •\n",
    "import json\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from Azure.model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB ì—°ê²°\n",
    "client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "db = client[config['path']['db_name']]\n",
    "collection = db[config['path']['collection_name']]\n",
    "\n",
    "# ChatModel ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "chat_model = ChatModel(config)\n",
    "\n",
    "print(\"MongoDB ì—°ê²° ë° ëª¨ë¸ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ë°ì´í„°ë² ì´ìŠ¤: {config['path']['db_name']}\")\n",
    "print(f\"ì»¬ë ‰ì…˜: {config['path']['collection_name']}\")\n",
    "print(f\"Top-k: {config['chat_config']['top_k']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec53806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Correctness ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œ IDë“¤ê³¼ ground truth IDë“¤ì„ ë¹„êµí•˜ì—¬ correctness ê³„ì‚°\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0\n",
    "    \n",
    "    # ground_truth_idsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì˜ˆ: \"['id1', 'id2']\" -> ['id1', 'id2'])\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ í•˜ë‚˜ë¼ë„ ground truthì— ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "    for doc_id in retrieved_doc_ids:\n",
    "        if doc_id in ground_truth_list:\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "print(\"Retrieval Correctness ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤\n",
    "def calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    Recall@k ê³„ì‚°: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ê´€ë ¨ ë¬¸ì„œì˜ ë¹„ìœ¨\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0.0\n",
    "    \n",
    "    # ground_truth_idsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # kê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ë§Œí¼ ì‚¬ìš©\n",
    "    if k is None:\n",
    "        k = len(retrieved_doc_ids)\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ë¬¸ì„œë§Œ ê³ ë ¤\n",
    "    top_k_retrieved = retrieved_doc_ids[:k]\n",
    "    \n",
    "    # ê´€ë ¨ ë¬¸ì„œ ìˆ˜ ê³„ì‚°\n",
    "    relevant_retrieved = sum(1 for doc_id in top_k_retrieved if doc_id in ground_truth_list)\n",
    "    \n",
    "    # Recall = ê´€ë ¨ ë¬¸ì„œ ìˆ˜ / ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ìˆ˜\n",
    "    if len(ground_truth_list) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return relevant_retrieved / len(ground_truth_list)\n",
    "\n",
    "\n",
    "def calculate_all_metrics(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ë©”íŠ¸ë¦­ì„ í•œ ë²ˆì— ê³„ì‚°\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"correctness\": calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids),\n",
    "        \"recall_at_k\": calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k)\n",
    "    }\n",
    "\n",
    "print(\"í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475036b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì •ëœ ëª¨ë¸ ë‹µë³€ ìƒì„± ë° ë¬¸ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ í•¨ìˆ˜ (ì¤‘ë³µ ê²€ìƒ‰ ì œê±°)\n",
    "def get_model_response_with_docs(query_text):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ë¡œë¶€í„° ë‹µë³€ì„ ìƒì„±í•˜ê³  ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n",
    "    ì´ì œ model.pyì˜ generate_ai_responseê°€ ê²€ìƒ‰ëœ ë¬¸ì„œ IDë„ í•¨ê»˜ ë°˜í™˜í•˜ë¯€ë¡œ ì¤‘ë³µ ê²€ìƒ‰ ì œê±°\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë¹ˆ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¡œ ì‹œì‘\n",
    "        conversation_history = []\n",
    "        \n",
    "        # ëª¨ë¸ ë‹µë³€ ìƒì„± (ì´ì œ ê²€ìƒ‰ëœ ë¬¸ì„œ IDë„ í•¨ê»˜ ë°˜í™˜ë¨)\n",
    "        response = chat_model.generate_ai_response(conversation_history, query_text, collection)\n",
    "        \n",
    "        # model.pyì—ì„œ ì´ë¯¸ ë°˜í™˜ëœ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "        return {\n",
    "            \"answer\": response[\"answer\"],\n",
    "            \"retrieved_doc_ids\": response[\"retrieved_doc_ids\"],\n",
    "            \"retrieved_docs\": response[\"retrieved_docs\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"\",\n",
    "            \"retrieved_doc_ids\": [],\n",
    "            \"retrieved_docs\": []\n",
    "        }\n",
    "\n",
    "print(\"ìˆ˜ì •ëœ ëª¨ë¸ ì‘ë‹µ ë° ë¬¸ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (ì¤‘ë³µ ê²€ìƒ‰ ì œê±°ë¨)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b778b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™•ì¥ëœ ë©”íŠ¸ë¦­ì„ ì‚¬ìš©í•œ í‰ê°€ ì‹¤í–‰\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë“¤\n",
    "baseline_results = []\n",
    "retrieved_doc_ids_list = []\n",
    "\n",
    "# ë©”íŠ¸ë¦­ë³„ ê²°ê³¼ ì €ì¥\n",
    "correctness_scores = []\n",
    "recall_at_k_scores = []\n",
    "precision_at_k_scores = []\n",
    "f1_at_k_scores = []\n",
    "\n",
    "print(f\"ì´ {len(query_df)}ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•´ í™•ì¥ëœ ë©”íŠ¸ë¦­ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# ê° ì¿¼ë¦¬ì— ëŒ€í•´ í‰ê°€ ì‹¤í–‰\n",
    "for idx, row in tqdm(query_df.iterrows(), total=len(query_df), desc=\"í™•ì¥ëœ ë©”íŠ¸ë¦­ í‰ê°€\"):\n",
    "    query_text = row['translated_4o_mini']\n",
    "    ground_truth_ids = row['ground_truth_id']\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{len(query_df)}] ì²˜ë¦¬ ì¤‘: {query_text[:50]}...\")\n",
    "    \n",
    "    # ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš© (ì¤‘ë³µ ê²€ìƒ‰ ì œê±°ë¨)\n",
    "    result = get_model_response_with_docs(query_text)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    baseline_results.append(result['answer'])\n",
    "    retrieved_doc_ids_list.append(result['retrieved_doc_ids'])\n",
    "    \n",
    "    # ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    metrics = calculate_all_metrics(result['retrieved_doc_ids'], ground_truth_ids)\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ ì €ì¥\n",
    "    correctness_scores.append(metrics['correctness'])\n",
    "    recall_at_k_scores.append(metrics['recall_at_k'])\n",
    "    \n",
    "    print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_doc_ids'])}\")\n",
    "    print(f\"Correctness: {metrics['correctness']}\")\n",
    "    print(f\"Recall@k: {metrics['recall_at_k']:.3f}\")\n",
    "    \n",
    "    # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ì ì‹œ ëŒ€ê¸°\n",
    "    time.sleep(1)\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n=== í™•ì¥ëœ ë©”íŠ¸ë¦­ í‰ê°€ ì™„ë£Œ! ===\")\n",
    "print(f\"í‰ê·  Correctness: {sum(correctness_scores) / len(correctness_scores):.3f}\")\n",
    "print(f\"í‰ê·  Recall@k: {sum(recall_at_k_scores) / len(recall_at_k_scores):.3f}\")\n",
    "\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì €ì¥ ë° CSV ë‚´ë³´ë‚´ê¸°\n",
    "import datetime\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ì— ìƒˆ ì»¬ëŸ¼ë“¤ ì¶”ê°€\n",
    "query_df['answer_baseline'] = baseline_results\n",
    "query_df['retrieved_doc_ids'] = retrieved_doc_ids_list\n",
    "query_df['correctness'] = correctness_scores\n",
    "query_df['recall_at_k'] = recall_at_k_scores\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "extended_metrics_csv_filename = f\"../data/extended_metrics_evaluation_results_{timestamp}.csv\"\n",
    "query_df.to_csv(extended_metrics_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"- answer_baseline: {len(baseline_results)}ê°œ\")\n",
    "print(f\"- retrieved_doc_ids: {len(retrieved_doc_ids_list)}ê°œ\") \n",
    "print(f\"- correctness: {len(correctness_scores)}ê°œ\")\n",
    "print(f\"- recall_at_k: {len(recall_at_k_scores)}ê°œ\")\n",
    "print(f\"- CSV íŒŒì¼: {extended_metrics_csv_filename}\")\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ìƒì„¸ ìš”ì•½\n",
    "total_queries = len(query_df)\n",
    "correct_retrievals = sum(correctness_scores)\n",
    "avg_correctness = correct_retrievals / total_queries\n",
    "avg_recall = sum(recall_at_k_scores) / len(recall_at_k_scores)\n",
    "\n",
    "print(f\"\\n=== í™•ì¥ëœ ë©”íŠ¸ë¦­ í‰ê°€ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "print(f\"ì´ ì¿¼ë¦¬ ìˆ˜: {total_queries}\")\n",
    "print(f\"ì •í™•í•œ ê²€ìƒ‰ ìˆ˜: {correct_retrievals}\")\n",
    "print(f\"í‰ê·  Correctness: {avg_correctness:.3f} ({avg_correctness*100:.1f}%)\")\n",
    "print(f\"í‰ê·  Recall@k: {avg_recall:.3f} ({avg_recall*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a651c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/extended_metrics_evaluation_results_20250916_203357.csv\")\n",
    "df.head()\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     print(len(ast.literal_eval(row[\"retrieved_doc_ids\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca8658",
   "metadata": {},
   "source": [
    "### ìƒˆë¡œìš´ ê²€ìƒ‰ ì„±ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1d1ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>translated_query</th>\n",
       "      <th>ì–¸ì–´</th>\n",
       "      <th>ground_truth_id</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "      <th>ì‘ì„±ì</th>\n",
       "      <th>ë¹„ê³ </th>\n",
       "      <th>ì†ŒìŠ¤</th>\n",
       "      <th>translated_4o_mini</th>\n",
       "      <th>keyword_4o_mini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì œ ì—¬ìì¹œêµ¬ê°€ ë‹¨ì†ìœ¼ë¡œ ì¶œì…êµ­ ë³´í˜¸ì†Œì— ìˆìŠµë‹ˆë‹¤. ì›”ê¸‰ì´ ì•„ì§ ë“¤ì–´ì˜¤ì§€ ì•Šì•˜ëŠ”ë°, ...</td>\n",
       "      <td>à¹à¸Ÿà¸™à¸‚à¸­à¸‡à¸œà¸¡à¸–à¸¹à¸à¸ˆà¸±à¸šà¸à¸¸à¸¡à¹à¸¥à¸°à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸¨à¸¹à¸™à¸¢à¹Œà¸à¸±à¸à¸•à¸±à¸§à¸•à¸£à¸§à¸ˆà¸„à¸™à¹€à¸‚...</td>\n",
       "      <td>íƒœêµ­ì–´</td>\n",
       "      <td>['689b3a86ffd306c1cd3c09a4', '689b3a86ffd306c1...</td>\n",
       "      <td>ì„ê¸ˆì²´ë¶ˆ</td>\n",
       "      <td>ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€</td>\n",
       "      <td>í™©ì˜ˆì›</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gmhr.or.kr/case/1529?sca=%EC%9E%84%EA%...</td>\n",
       "      <td>ì œ ì—¬ìì¹œêµ¬ê°€ ì²´í¬ë˜ì–´ ì¶œì…êµ­ ê´€ë¦¬ì†Œì— êµ¬ê¸ˆë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì›”ê¸‰ì„ ë°›ì§€ ëª»í–ˆëŠ”...</td>\n",
       "      <td>['ì²´í¬', 'ì¶œì…êµ­ ê´€ë¦¬ì†Œ', 'ì›”ê¸‰', 'ë°€ë¦° ì›”ê¸‰']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”, ê±´ì„¤ í˜„ì¥ì—ì„œ ì¼í•˜ê³  ìˆëŠ” ì‚¬ëŒì¸ë°, ì‚¬ì¥ë‹˜ì´ ì›”ê¸‰ì„ ì•ˆì¤˜ì„œ ê³„ì¢Œê°€ ì••...</td>\n",
       "      <td>ä½ å¥½ï¼Œæˆ‘æ˜¯åœ¨å»ºç­‘å·¥åœ°å·¥ä½œçš„ï¼Œä½†è€æ¿æ²¡æœ‰å‘å·¥èµ„ï¼Œæˆ‘çš„è´¦æˆ·å¯èƒ½ä¼šè¢«æŸ¥å°ã€‚é‡åˆ°è¿™ç§æƒ…å†µè¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ</td>\n",
       "      <td>ì¤‘êµ­ì–´</td>\n",
       "      <td>['689b3a86ffd306c1cd3c06e8', '689b3a86ffd306c1...</td>\n",
       "      <td>ì„ê¸ˆì²´ë¶ˆ</td>\n",
       "      <td>ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€</td>\n",
       "      <td>í™©ì˜ˆì›</td>\n",
       "      <td>ì„ê¸ˆì²´ë¶ˆ ë° \"ì••ë¥˜ë°©ì§€ í†µì¥\" (=ì„ê¸ˆì±„ê¶Œ ì „ìš©í†µì¥) ê´€ë ¨ ë°ì´í„° í•„ìš”</td>\n",
       "      <td>https://gmhr.or.kr/case/1493?sca=%EC%9E%84%EA%...</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ê±´ì„¤ í˜„ì¥ì—ì„œ ì¼í•˜ê³  ìˆëŠ”ë°, ì‚¬ì¥ì´ ê¸‰ì—¬ë¥¼ ì§€ê¸‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤....</td>\n",
       "      <td>['ê±´ì„¤ì—…', 'ì„ê¸ˆì²´ë¶ˆ', 'ê³„ì¢Œ ì••ë¥˜']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í•„ë¦¬í•€ì—ì„œ ì˜¨ ë…¸ë™ìì…ë‹ˆë‹¤. 5ë…„ ë™ì•ˆ ê·¼ë¬´ë¥¼ í•˜ê³  ì´ì œ ì œ ë‚˜ë¼...</td>\n",
       "      <td>Magandang araw, ako ay isang manggagawang mula...</td>\n",
       "      <td>í•„ë¦¬í•€ì–´ (íƒ€ê°ˆë¡œê·¸ì–´)</td>\n",
       "      <td>['689b3a86ffd306c1cd3c09a4']</td>\n",
       "      <td>ì„ê¸ˆì²´ë¶ˆ</td>\n",
       "      <td>ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€</td>\n",
       "      <td>í™©ì˜ˆì›</td>\n",
       "      <td>ì²´ë‹¹ê¸ˆ ê´€ë ¨ ë°ì´í„° í•„ìš”</td>\n",
       "      <td>https://gmhr.or.kr/case/1667?sca=%EC%9E%84%EA%...</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í•„ë¦¬í•€ì—ì„œ ì˜¨ ë…¸ë™ìì…ë‹ˆë‹¤. 5ë…„ ë™ì•ˆ ì¼í–ˆëŠ”ë° ì´ì œ ê³ êµ­ìœ¼ë¡œ ëŒ...</td>\n",
       "      <td>['ì„ê¸ˆì²´ë¶ˆ', 'íšŒìˆ˜ ë°©ë²•']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì‚¬ì—…ì¥ ë³€ê²½ ì‹ ì²­ ì´í›„ ì œê°€ ë¶ˆë²•ì²´ë¥˜ìê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ìš°í¸ì´ ë‚ ì•„ì™”ì–´ìš”. 8ì›” 2...</td>\n",
       "      <td>åœ¨ç”³è¯·å˜æ›´å·¥ä½œå•ä½ä¹‹åï¼Œæˆ‘æ”¶åˆ°äº†ä¸€å°ä¿¡ï¼Œè¯´æˆ‘å¯èƒ½ä¼šå˜æˆéæ³•æ»ç•™è€…ã€‚åªè¢«å…è®¸åœç•™åˆ°8æœˆ22æ—¥ï¼Œ...</td>\n",
       "      <td>ì¤‘êµ­ì–´</td>\n",
       "      <td>['689b3a86ffd306c1cd3c0680', '689b3a86ffd306c1...</td>\n",
       "      <td>ì²´ë¥˜ìê²©</td>\n",
       "      <td>ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€</td>\n",
       "      <td>í™©ì˜ˆì›</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gmhr.or.kr/case/1679?sca=%EC%B2%B4%EB%...</td>\n",
       "      <td>ì‚¬ì—…ì¥ ë³€ê²½ì„ ì‹ ì²­í•œ í›„, ì œê°€ ë¶ˆë²• ì²´ë¥˜ìê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ë‚´ìš©ì˜ í¸ì§€ë¥¼ ë°›ì•˜ìŠµë‹ˆ...</td>\n",
       "      <td>['ì‚¬ì—…ì¥ ë³€ê²½', 'ë¶ˆë²• ì²´ë¥˜', 'ì¶”ë°©', 'ì²´ë¥˜ í—ˆìš© ê¸°ê°„']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì œê°€ ì¤‘ê°„ì— í‡´ì§ì„ í•˜ê²Œ ë˜ì—ˆëŠ”ë°, ì†Œë“ì„¸ê°€ ì²´ë‚©ë˜ì–´ ë¹„ì ì—°ì¥ì´ ì•ˆëœëŒ€ìš”. ê·¸ëŸ°ë°...</td>\n",
       "      <td>æˆ‘ä¸­é€”ç¦»èŒäº†ï¼Œä½†æ˜¯å› ä¸ºæ‹–æ¬ æ‰€å¾—ç¨ï¼Œç­¾è¯æ— æ³•å»¶æœŸã€‚å¯æ˜¯æˆ‘å¬ä¸æ‡‚ç›¸å…³çš„é€šçŸ¥å†…å®¹ã€‚</td>\n",
       "      <td>ì¤‘êµ­ì–´</td>\n",
       "      <td>['689b3a86ffd306c1cd3c08f8', '689b3a86ffd306c1...</td>\n",
       "      <td>ì²´ë¥˜ìê²©</td>\n",
       "      <td>ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€</td>\n",
       "      <td>í™©ì˜ˆì›</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://gmhr.or.kr/case/1703?sca=%EC%B2%B4%EB%...</td>\n",
       "      <td>ì €ëŠ” ì¤‘ê°„ì— í‡´ì‚¬í–ˆì§€ë§Œ, ì†Œë“ì„¸ ì²´ë‚© ë•Œë¬¸ì— ë¹„ìë¥¼ ì—°ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ê´€...</td>\n",
       "      <td>['í‡´ì‚¬', 'ì†Œë“ì„¸ ì²´ë‚©', 'ë¹„ì ì—°ì¥', 'í†µì§€ ë‚´ìš©']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  ì œ ì—¬ìì¹œêµ¬ê°€ ë‹¨ì†ìœ¼ë¡œ ì¶œì…êµ­ ë³´í˜¸ì†Œì— ìˆìŠµë‹ˆë‹¤. ì›”ê¸‰ì´ ì•„ì§ ë“¤ì–´ì˜¤ì§€ ì•Šì•˜ëŠ”ë°, ...   \n",
       "1  ì•ˆë…•í•˜ì„¸ìš”, ê±´ì„¤ í˜„ì¥ì—ì„œ ì¼í•˜ê³  ìˆëŠ” ì‚¬ëŒì¸ë°, ì‚¬ì¥ë‹˜ì´ ì›”ê¸‰ì„ ì•ˆì¤˜ì„œ ê³„ì¢Œê°€ ì••...   \n",
       "2  ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í•„ë¦¬í•€ì—ì„œ ì˜¨ ë…¸ë™ìì…ë‹ˆë‹¤. 5ë…„ ë™ì•ˆ ê·¼ë¬´ë¥¼ í•˜ê³  ì´ì œ ì œ ë‚˜ë¼...   \n",
       "3  ì‚¬ì—…ì¥ ë³€ê²½ ì‹ ì²­ ì´í›„ ì œê°€ ë¶ˆë²•ì²´ë¥˜ìê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ìš°í¸ì´ ë‚ ì•„ì™”ì–´ìš”. 8ì›” 2...   \n",
       "4  ì œê°€ ì¤‘ê°„ì— í‡´ì§ì„ í•˜ê²Œ ë˜ì—ˆëŠ”ë°, ì†Œë“ì„¸ê°€ ì²´ë‚©ë˜ì–´ ë¹„ì ì—°ì¥ì´ ì•ˆëœëŒ€ìš”. ê·¸ëŸ°ë°...   \n",
       "\n",
       "                                    translated_query            ì–¸ì–´  \\\n",
       "0  à¹à¸Ÿà¸™à¸‚à¸­à¸‡à¸œà¸¡à¸–à¸¹à¸à¸ˆà¸±à¸šà¸à¸¸à¸¡à¹à¸¥à¸°à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¸¨à¸¹à¸™à¸¢à¹Œà¸à¸±à¸à¸•à¸±à¸§à¸•à¸£à¸§à¸ˆà¸„à¸™à¹€à¸‚...           íƒœêµ­ì–´   \n",
       "1     ä½ å¥½ï¼Œæˆ‘æ˜¯åœ¨å»ºç­‘å·¥åœ°å·¥ä½œçš„ï¼Œä½†è€æ¿æ²¡æœ‰å‘å·¥èµ„ï¼Œæˆ‘çš„è´¦æˆ·å¯èƒ½ä¼šè¢«æŸ¥å°ã€‚é‡åˆ°è¿™ç§æƒ…å†µè¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ           ì¤‘êµ­ì–´   \n",
       "2  Magandang araw, ako ay isang manggagawang mula...  í•„ë¦¬í•€ì–´ (íƒ€ê°ˆë¡œê·¸ì–´)   \n",
       "3  åœ¨ç”³è¯·å˜æ›´å·¥ä½œå•ä½ä¹‹åï¼Œæˆ‘æ”¶åˆ°äº†ä¸€å°ä¿¡ï¼Œè¯´æˆ‘å¯èƒ½ä¼šå˜æˆéæ³•æ»ç•™è€…ã€‚åªè¢«å…è®¸åœç•™åˆ°8æœˆ22æ—¥ï¼Œ...           ì¤‘êµ­ì–´   \n",
       "4             æˆ‘ä¸­é€”ç¦»èŒäº†ï¼Œä½†æ˜¯å› ä¸ºæ‹–æ¬ æ‰€å¾—ç¨ï¼Œç­¾è¯æ— æ³•å»¶æœŸã€‚å¯æ˜¯æˆ‘å¬ä¸æ‡‚ç›¸å…³çš„é€šçŸ¥å†…å®¹ã€‚           ì¤‘êµ­ì–´   \n",
       "\n",
       "                                     ground_truth_id category  \\\n",
       "0  ['689b3a86ffd306c1cd3c09a4', '689b3a86ffd306c1...     ì„ê¸ˆì²´ë¶ˆ   \n",
       "1  ['689b3a86ffd306c1cd3c06e8', '689b3a86ffd306c1...     ì„ê¸ˆì²´ë¶ˆ   \n",
       "2                       ['689b3a86ffd306c1cd3c09a4']     ì„ê¸ˆì²´ë¶ˆ   \n",
       "3  ['689b3a86ffd306c1cd3c0680', '689b3a86ffd306c1...     ì²´ë¥˜ìê²©   \n",
       "4  ['689b3a86ffd306c1cd3c08f8', '689b3a86ffd306c1...     ì²´ë¥˜ìê²©   \n",
       "\n",
       "            source  ì‘ì„±ì                                       ë¹„ê³   \\\n",
       "0  ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€  í™©ì˜ˆì›                                      NaN   \n",
       "1  ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€  í™©ì˜ˆì›  ì„ê¸ˆì²´ë¶ˆ ë° \"ì••ë¥˜ë°©ì§€ í†µì¥\" (=ì„ê¸ˆì±„ê¶Œ ì „ìš©í†µì¥) ê´€ë ¨ ë°ì´í„° í•„ìš”   \n",
       "2  ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€  í™©ì˜ˆì›                            ì²´ë‹¹ê¸ˆ ê´€ë ¨ ë°ì´í„° í•„ìš”   \n",
       "3  ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€  í™©ì˜ˆì›                                      NaN   \n",
       "4  ê²½ê¸°ë„ì™¸êµ­ì¸ì§€ì›ì„¼í„°_ìƒë‹´ì‚¬ë¡€  í™©ì˜ˆì›                                      NaN   \n",
       "\n",
       "                                                  ì†ŒìŠ¤  \\\n",
       "0  https://gmhr.or.kr/case/1529?sca=%EC%9E%84%EA%...   \n",
       "1  https://gmhr.or.kr/case/1493?sca=%EC%9E%84%EA%...   \n",
       "2  https://gmhr.or.kr/case/1667?sca=%EC%9E%84%EA%...   \n",
       "3  https://gmhr.or.kr/case/1679?sca=%EC%B2%B4%EB%...   \n",
       "4  https://gmhr.or.kr/case/1703?sca=%EC%B2%B4%EB%...   \n",
       "\n",
       "                                  translated_4o_mini  \\\n",
       "0  ì œ ì—¬ìì¹œêµ¬ê°€ ì²´í¬ë˜ì–´ ì¶œì…êµ­ ê´€ë¦¬ì†Œì— êµ¬ê¸ˆë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì›”ê¸‰ì„ ë°›ì§€ ëª»í–ˆëŠ”...   \n",
       "1  ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ê±´ì„¤ í˜„ì¥ì—ì„œ ì¼í•˜ê³  ìˆëŠ”ë°, ì‚¬ì¥ì´ ê¸‰ì—¬ë¥¼ ì§€ê¸‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤....   \n",
       "2  ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í•„ë¦¬í•€ì—ì„œ ì˜¨ ë…¸ë™ìì…ë‹ˆë‹¤. 5ë…„ ë™ì•ˆ ì¼í–ˆëŠ”ë° ì´ì œ ê³ êµ­ìœ¼ë¡œ ëŒ...   \n",
       "3  ì‚¬ì—…ì¥ ë³€ê²½ì„ ì‹ ì²­í•œ í›„, ì œê°€ ë¶ˆë²• ì²´ë¥˜ìê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ë‚´ìš©ì˜ í¸ì§€ë¥¼ ë°›ì•˜ìŠµë‹ˆ...   \n",
       "4  ì €ëŠ” ì¤‘ê°„ì— í‡´ì‚¬í–ˆì§€ë§Œ, ì†Œë“ì„¸ ì²´ë‚© ë•Œë¬¸ì— ë¹„ìë¥¼ ì—°ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ê´€...   \n",
       "\n",
       "                         keyword_4o_mini  \n",
       "0       ['ì²´í¬', 'ì¶œì…êµ­ ê´€ë¦¬ì†Œ', 'ì›”ê¸‰', 'ë°€ë¦° ì›”ê¸‰']  \n",
       "1               ['ê±´ì„¤ì—…', 'ì„ê¸ˆì²´ë¶ˆ', 'ê³„ì¢Œ ì••ë¥˜']  \n",
       "2                      ['ì„ê¸ˆì²´ë¶ˆ', 'íšŒìˆ˜ ë°©ë²•']  \n",
       "3  ['ì‚¬ì—…ì¥ ë³€ê²½', 'ë¶ˆë²• ì²´ë¥˜', 'ì¶”ë°©', 'ì²´ë¥˜ í—ˆìš© ê¸°ê°„']  \n",
       "4     ['í‡´ì‚¬', 'ì†Œë“ì„¸ ì²´ë‚©', 'ë¹„ì ì—°ì¥', 'í†µì§€ ë‚´ìš©']  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "query_df = pd.read_csv(\"../data/helloworld_test_query_with_translation_20250916_192212.csv\")\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1184cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ ì„¤ì • ì™„ë£Œ\n",
      "í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ í‰ê°€\n",
    "from Azure.keyword_model import ChatModel as KeywordChatModel\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# í™˜ê²½ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# í‚¤ì›Œë“œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "keyword_chat_model = KeywordChatModel(config)\n",
    "\n",
    "print(\"í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜\n",
    "def get_keyword_model_response_with_docs(query_text, keywords):\n",
    "    \"\"\"\n",
    "    í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ë¡œë¶€í„° ë‹µë³€ì„ ìƒì„±í•˜ê³  ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë¹ˆ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¡œ ì‹œì‘\n",
    "        conversation_history = []\n",
    "        \n",
    "        # í‚¤ì›Œë“œ ê¸°ë°˜ ëª¨ë¸ ë‹µë³€ ìƒì„±\n",
    "        response = keyword_chat_model.generate_ai_response(\n",
    "            conversation_history, \n",
    "            query_text, \n",
    "            collection, \n",
    "            keywords=keywords\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response[\"answer\"],\n",
    "            \"retrieved_doc_ids\": response[\"retrieved_doc_ids\"],\n",
    "            \"retrieved_docs\": response[\"retrieved_docs\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"\",\n",
    "            \"retrieved_doc_ids\": [],\n",
    "            \"retrieved_docs\": []\n",
    "        }\n",
    "\n",
    "print(\"í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0ee1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Correctness ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Retrieval Correctness ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œ IDë“¤ê³¼ ground truth IDë“¤ì„ ë¹„êµí•˜ì—¬ correctness ê³„ì‚°\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0\n",
    "    \n",
    "    # ground_truth_idsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì˜ˆ: \"['id1', 'id2']\" -> ['id1', 'id2'])\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ í•˜ë‚˜ë¼ë„ ground truthì— ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "    for doc_id in retrieved_doc_ids:\n",
    "        if doc_id in ground_truth_list:\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "print(\"Retrieval Correctness ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤\n",
    "def calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    Recall@k ê³„ì‚°: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ê´€ë ¨ ë¬¸ì„œì˜ ë¹„ìœ¨\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0.0\n",
    "    \n",
    "    # ground_truth_idsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # kê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ë§Œí¼ ì‚¬ìš©\n",
    "    if k is None:\n",
    "        k = len(retrieved_doc_ids)\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ë¬¸ì„œë§Œ ê³ ë ¤\n",
    "    top_k_retrieved = retrieved_doc_ids[:k]\n",
    "    \n",
    "    # ê´€ë ¨ ë¬¸ì„œ ìˆ˜ ê³„ì‚°\n",
    "    relevant_retrieved = sum(1 for doc_id in top_k_retrieved if doc_id in ground_truth_list)\n",
    "    \n",
    "    # Recall = ê´€ë ¨ ë¬¸ì„œ ìˆ˜ / ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ìˆ˜\n",
    "    if len(ground_truth_list) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return relevant_retrieved / len(ground_truth_list)\n",
    "\n",
    "\n",
    "def calculate_all_metrics(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ë©”íŠ¸ë¦­ì„ í•œ ë²ˆì— ê³„ì‚°\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"correctness\": calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids),\n",
    "        \"recall_at_k\": calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k)\n",
    "    }\n",
    "\n",
    "print(\"í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff122916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "==================================================\n",
      "ğŸ”— MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì™„ë£Œ\n",
      "âœ… MongoDB ì—°ê²° ì„±ê³µ!\n",
      "ğŸ“Š MongoDB ë²„ì „: 8.0.13\n",
      "ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤: ['HelloWorld-AI', 'admin', 'local']\n",
      "ğŸ¯ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤: HelloWorld-AI\n",
      "ğŸ“‹ ì»¬ë ‰ì…˜ ëª©ë¡: ['foreigner_legalQA_v2', 'foreigner_legal_test', 'foreigner_legalQA', 'foreigner_legalQA_v3']\n",
      "ğŸ¯ íƒ€ê²Ÿ ì»¬ë ‰ì…˜: foreigner_legalQA_v3\n",
      "ğŸ“ˆ ë¬¸ì„œ ê°œìˆ˜: 867\n",
      "ğŸ’¾ ì»¬ë ‰ì…˜ í¬ê¸°: 37,616,750 bytes (35.87 MB)\n",
      "ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ í‚¤: ['_id', 'title', 'contents', 'url', 'Embedding']\n",
      "ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ ID: 689b3a86ffd306c1cd3c0679\n",
      "ğŸ” ì¸ë±ìŠ¤ ì •ë³´:\n",
      "   - _id_: SON([('_id', 1)])\n",
      "==================================================\n",
      "âœ… MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "import json\n",
    "import os\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²°\n",
    "mongodb_client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "print(\"ğŸ”— MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì™„ë£Œ\")\n",
    "\n",
    "try:\n",
    "    # ì—°ê²° ìƒíƒœ í™•ì¸\n",
    "    mongodb_client.admin.command('ping')\n",
    "    print(\"âœ… MongoDB ì—°ê²° ì„±ê³µ!\")\n",
    "    \n",
    "    # ì„œë²„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    server_info = mongodb_client.server_info()\n",
    "    print(f\"ğŸ“Š MongoDB ë²„ì „: {server_info['version']}\")\n",
    "    \n",
    "    # ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ í™•ì¸\n",
    "    db_list = mongodb_client.list_database_names()\n",
    "    print(f\"ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤: {db_list}\")\n",
    "    \n",
    "    # í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´\n",
    "    current_db = mongodb_client[config['path']['db_name']]\n",
    "    print(f\"ğŸ¯ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤: {config['path']['db_name']}\")\n",
    "    \n",
    "    # ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸\n",
    "    collections = current_db.list_collection_names()\n",
    "    print(f\"ğŸ“‹ ì»¬ë ‰ì…˜ ëª©ë¡: {collections}\")\n",
    "    \n",
    "    # íƒ€ê²Ÿ ì»¬ë ‰ì…˜ í™•ì¸\n",
    "    target_collection = current_db[config['path']['collection_name']]\n",
    "    print(f\"ğŸ¯ íƒ€ê²Ÿ ì»¬ë ‰ì…˜: {config['path']['collection_name']}\")\n",
    "    \n",
    "    # ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´\n",
    "    stats = current_db.command(\"collStats\", config['path']['collection_name'])\n",
    "    print(f\"ğŸ“ˆ ë¬¸ì„œ ê°œìˆ˜: {stats['count']:,}\")\n",
    "    print(f\"ğŸ’¾ ì»¬ë ‰ì…˜ í¬ê¸°: {stats['size']:,} bytes ({stats['size']/1024/1024:.2f} MB)\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë¬¸ì„œ í™•ì¸\n",
    "    sample_doc = target_collection.find_one()\n",
    "    if sample_doc:\n",
    "        print(f\"ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ í‚¤: {list(sample_doc.keys())}\")\n",
    "        print(f\"ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ ID: {sample_doc.get('_id', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì»¬ë ‰ì…˜ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ì¸ë±ìŠ¤ ì •ë³´ í™•ì¸\n",
    "    indexes = target_collection.list_indexes()\n",
    "    print(f\"ğŸ” ì¸ë±ìŠ¤ ì •ë³´:\")\n",
    "    for idx in indexes:\n",
    "        print(f\"   - {idx['name']}: {idx['key']}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"âœ… MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print(f\"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "except pymongo.errors.ServerSelectionTimeoutError as e:\n",
    "    print(f\"âŒ ì„œë²„ ì„ íƒ íƒ€ì„ì•„ì›ƒ: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a051a49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB ì—°ê²° ë° ëª¨ë¸ ì„¤ì • ì™„ë£Œ\n",
      "ë°ì´í„°ë² ì´ìŠ¤: HelloWorld-AI\n",
      "ì»¬ë ‰ì…˜: foreigner_legalQA_v3\n",
      "Top-k: 20\n"
     ]
    }
   ],
   "source": [
    "# MongoDB ì—°ê²° ë° ëª¨ë¸ ì„¤ì •\n",
    "import json\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "from Azure.model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB ì—°ê²°\n",
    "client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "db = client[config['path']['db_name']]\n",
    "collection = db[config['path']['collection_name']]\n",
    "\n",
    "# ChatModel ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "chat_model = ChatModel(config)\n",
    "\n",
    "print(\"MongoDB ì—°ê²° ë° ëª¨ë¸ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"ë°ì´í„°ë² ì´ìŠ¤: {config['path']['db_name']}\")\n",
    "print(f\"ì»¬ë ‰ì…˜: {config['path']['collection_name']}\")\n",
    "print(f\"Top-k: {config['chat_config']['top_k']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff703b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'translated_query', 'ì–¸ì–´', 'ground_truth_id', 'category',\n",
       "       'source', 'ì‘ì„±ì', 'ë¹„ê³ ', 'ì†ŒìŠ¤', 'translated_4o_mini', 'keyword_4o_mini'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a11cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 20ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•´ í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/20] ì²˜ë¦¬ ì¤‘: ì œ ì—¬ìì¹œêµ¬ê°€ ì²´í¬ë˜ì–´ ì¶œì…êµ­ ê´€ë¦¬ì†Œì— êµ¬ê¸ˆë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì§€ê¸ˆ ì›”ê¸‰ì„ ë°›ì§€ ëª»í–ˆëŠ”ë°, ë§Œ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì²´í¬', 'ì¶œì…êµ­ ê´€ë¦¬ì†Œ', 'ì›”ê¸‰', 'ë°€ë¦° ì›”ê¸‰']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:   5%|â–Œ         | 1/20 [00:13<04:13, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/20] ì²˜ë¦¬ ì¤‘: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ê±´ì„¤ í˜„ì¥ì—ì„œ ì¼í•˜ê³  ìˆëŠ”ë°, ì‚¬ì¥ì´ ê¸‰ì—¬ë¥¼ ì§€ê¸‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì œ ê³„...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ê±´ì„¤ì—…', 'ì„ê¸ˆì²´ë¶ˆ', 'ê³„ì¢Œ ì••ë¥˜']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  10%|â–ˆ         | 2/20 [00:24<03:40, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/20] ì²˜ë¦¬ ì¤‘: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” í•„ë¦¬í•€ì—ì„œ ì˜¨ ë…¸ë™ìì…ë‹ˆë‹¤. 5ë…„ ë™ì•ˆ ì¼í–ˆëŠ”ë° ì´ì œ ê³ êµ­ìœ¼ë¡œ ëŒì•„ê°€ë ¤ê³ ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì„ê¸ˆì²´ë¶ˆ', 'íšŒìˆ˜ ë°©ë²•']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  15%|â–ˆâ–Œ        | 3/20 [00:35<03:13, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/20] ì²˜ë¦¬ ì¤‘: ì‚¬ì—…ì¥ ë³€ê²½ì„ ì‹ ì²­í•œ í›„, ì œê°€ ë¶ˆë²• ì²´ë¥˜ìê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ë‚´ìš©ì˜ í¸ì§€ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤. 8...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì‚¬ì—…ì¥ ë³€ê²½', 'ë¶ˆë²• ì²´ë¥˜', 'ì¶”ë°©', 'ì²´ë¥˜ í—ˆìš© ê¸°ê°„']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  20%|â–ˆâ–ˆ        | 4/20 [00:45<02:58, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/20] ì²˜ë¦¬ ì¤‘: ì €ëŠ” ì¤‘ê°„ì— í‡´ì‚¬í–ˆì§€ë§Œ, ì†Œë“ì„¸ ì²´ë‚© ë•Œë¬¸ì— ë¹„ìë¥¼ ì—°ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ê´€ë ¨ëœ í†µ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['í‡´ì‚¬', 'ì†Œë“ì„¸ ì²´ë‚©', 'ë¹„ì ì—°ì¥', 'í†µì§€ ë‚´ìš©']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:57<02:50, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/20] ì²˜ë¦¬ ì¤‘: íšŒì‚¬ê°€ ê°‘ìê¸° ë” ì´ìƒ ì¶œê·¼í•˜ì§€ ë§ë¼ê³  í•´ì„œ, ì²´ë¥˜ ìê²©ì´ ë°•íƒˆë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì²´ë¥˜ ìê²© ë°•íƒˆ', 'ëŒ€ì²˜ ë°©ë²•']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [01:07<02:29, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/20] ì²˜ë¦¬ ì¤‘: ì €ëŠ” ê±´ì„¤ì—…ì—ì„œ ì¼í•˜ê³  ìˆëŠ” ì™¸êµ­ì¸ ë…¸ë™ìì…ë‹ˆë‹¤. ì–´ë–¤ ê²½ìš°ê°€ ì‚°ì—…ì¬í•´ë¡œ ê°„ì£¼ë˜ëŠ”ì§€ ì•Œê³  ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì™¸êµ­ì¸ ë…¸ë™ì', 'ê±´ì„¤ì—…', 'ì‚°ì—…ì¬í•´', 'ë³´ìƒ']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [01:18<02:20, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8/20] ì²˜ë¦¬ ì¤‘: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ë² íŠ¸ë‚¨ì— ê±°ì£¼ ì¤‘ì¸ ì¬ì™¸ë™í¬ì…ë‹ˆë‹¤. ì´ë²ˆì— íŠ¹ë¡€ê³ ìš©í—ˆê°€ì œë¥¼ í†µí•´ í•œêµ­ì—ì„œ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì¬ì™¸ë™í¬', 'íŠ¹ë¡€ê³ ìš©í—ˆê°€ì œ', 'ì ˆì°¨']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:30<02:16, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9/20] ì²˜ë¦¬ ì¤‘: ì €ëŠ” H-2 ë¹„ìë¥¼ ê°€ì§€ê³  ìˆëŠ”ë°, í˜„ì¬ ê³ ìš©ì£¼ë¥¼ ë– ë‚˜ ë‹¤ë¥¸ ì§ì¥ìœ¼ë¡œ ì˜®ê¸¸ ìˆ˜ ìˆëŠ”ì§€ ê¶ê¸ˆ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['H-2 ë¹„ì', 'ì‚¬ì—…ì¥ ë³€ê²½', 'ì ˆì°¨', 'ì§€ì› ì„œë¥˜']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:40<01:58, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10/20] ì²˜ë¦¬ ì¤‘: ê³ ìš©ì£¼ê°€ ì§€ì†ì ìœ¼ë¡œ ì„ê¸ˆì„ ì²´ë¶ˆí•˜ì—¬ ì €ëŠ” ê·¼ë¬´ì§€ë¥¼ ì˜®ê¸°ê³  ì‹¶ìŠµë‹ˆë‹¤....\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì„ê¸ˆì²´ë¶ˆ', 'ê·¼ë¬´ì§€ ë³€ê²½']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:51<01:50, 11.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[11/20] ì²˜ë¦¬ ì¤‘: ì‹¤ì—…ê¸‰ì—¬ë¥¼ ë°›ê³  ìˆëŠ” ì¤‘ì— ì¡°ê¸° ì¬ì·¨ì—…ì„ í•˜ë©´ 'ì¡°ê¸° ì¬ì·¨ì—… ìˆ˜ë‹¹'ì„ ë°›ì„ ìˆ˜ ìˆë‹¤ê³  ë“¤ì—ˆ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì‹¤ì—…ê¸‰ì—¬', 'ì¡°ê¸° ì¬ì·¨ì—… ìˆ˜ë‹¹', 'ê·¼ë¬´ ê¸°ê°„', 'ì§€ê¸‰ ì œí•œ']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [02:03<01:40, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[12/20] ì²˜ë¦¬ ì¤‘: E-9 ë¹„ìë¥¼ ê°€ì§„ ë¹„ì „ë¬¸ ì·¨ì—… ì™¸êµ­ì¸ ë…¸ë™ìê°€ ì‚¬ì—…ì¥ì´ íì—…í•˜ê±°ë‚˜ ì„ê¸ˆ ì²´ë¶ˆ ë“±ì˜ ì´ìœ ë¡œ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['E-9 ë¹„ì', 'ì‚¬ì—…ì¥ ë³€ê²½', 'ì„ê¸ˆ ì²´ë¶ˆ', 'ì‹ ì²­ ê¸°í•œ']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [02:09<01:17,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[13/20] ì²˜ë¦¬ ì¤‘: ê·¼ë¡œê³„ì•½ì´ ì¢…ë£Œëœ í›„, ë§Œì•½ ê·¼ë¬´ì§€ë¥¼ ë³€ê²½í•˜ê³  ì‹¶ë‹¤ë©´ ì–¸ì œê¹Œì§€ ê³ ìš©ì„¼í„°ì— ì‹ ì²­ì„œë¥¼ ì œì¶œí•´ì•¼...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ê·¼ë¡œê³„ì•½ ì¢…ë£Œ', 'ê·¼ë¬´ì§€ ë³€ê²½', 'ê³ ìš©ì„¼í„°', 'ì‹ ì²­ì„œ ì œì¶œ', 'ì¼ìë¦¬ ë¯¸ë°œê²¬']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [02:16<01:01,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[14/20] ì²˜ë¦¬ ì¤‘: E-9 ë¹„ìë¥¼ ê°€ì§„ ì™¸êµ­ì¸ ë…¸ë™ìê°€ ê·¼ë¬´ ì¡°ê±´ì´ ê·¼ë¡œê³„ì•½ê³¼ ë‹¤ë¥´ë‹¤ê³  ì£¼ì¥í•  ê²½ìš°, ì´ ìƒí™©...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['E-9 ë¹„ì', 'ê·¼ë¡œê³„ì•½', 'ì‚¬ì—…ì¥ ë³€ê²½', 'ì ˆì°¨']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [02:29<01:00, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15/20] ì²˜ë¦¬ ì¤‘: ë¹„ì ë§Œë£Œ ì „ì— ì—°ì¥ì„ ì‹ ì²­í•˜ê³  ì‹¶ë‹¤ë©´ ì–´ë–¤ ê¸°ê´€ì— ê°€ì•¼ í•˜ê³ , ì˜¨ë¼ì¸ìœ¼ë¡œë„ ì‹ ì²­í•  ìˆ˜ ìˆ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ë¹„ì ì—°ì¥', 'ì‹ ì²­ ê¸°ê´€', 'ì˜¨ë¼ì¸ ì‹ ì²­']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [02:37<00:46,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[16/20] ì²˜ë¦¬ ì¤‘: ì„¸ê¸ˆì´ë‚˜ ê±´ê°•ë³´í—˜ ê¸°ì—¬ê¸ˆì´ ë¯¸ë‚©ëœ ê²½ìš° ë¹„ì ê°±ì‹ ì´ ê°€ëŠ¥í•œê°€ìš”? ê·¸ë¦¬ê³  ë§Œì•½ ë¹šì´ ìˆë‹¤ë©´ ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ë¹„ì ê°±ì‹ ', 'ì„¸ê¸ˆ ë¯¸ë‚©', 'ê±´ê°•ë³´í—˜ ê¸°ì—¬ê¸ˆ', 'ì²˜ë²Œ']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [02:49<00:40, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[17/20] ì²˜ë¦¬ ì¤‘: ê·¼ë¬´ ì¤‘ì— ë¶€ìƒì„ ë‹¹í•´ ë³‘ì›ì—ì„œ ì¹˜ë£Œë¥¼ ë°›ì•„ì•¼ í•˜ëŠ” ê²½ìš°, ë§Œì•½ ê³ ìš©ì£¼ê°€ ì‚°ì—…ì¬í•´ ë³´í—˜ì— ...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ë¶€ìƒ', 'ë³´ìƒ', 'ì‚°ì—…ì¬í•´ ë³´í—˜', 'ë¬¸ì˜ì²˜']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [03:00<00:31, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[18/20] ì²˜ë¦¬ ì¤‘: ê·¼ë¬´ ì¤‘ ì „ì—¼ë³‘ì— ê°ì—¼ë˜ì—ˆì„ ë•Œ, ì´ë¥¼ ì—…ë¬´ìƒ ì§ˆë³‘ìœ¼ë¡œ ì¸ì •í•˜ê¸° ìœ„í•´ ì–´ë–¤ ê¸°ì¤€ì´ ì‚¬ìš©ë˜ë‚˜...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ì „ì—¼ë³‘', 'ì—…ë¬´ìƒ ì§ˆë³‘', 'ê¸°ì¤€']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 1\n",
      "Recall@k: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [03:11<00:21, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[19/20] ì²˜ë¦¬ ì¤‘: í•´ì™¸ ë§Œê¸° ë³´í—˜ê¸ˆì„ ì‹ ì²­í•˜ë ¤ë©´ ì–´ë–¤ ìê²© ì¡°ê±´ì„ ì¶©ì¡±í•´ì•¼ í•˜ë‚˜ìš”? ì–¸ì œë¶€í„° ì‹ ì²­í•  ìˆ˜ ìˆë‚˜...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['í•´ì™¸ ë§Œê¸° ë³´í—˜ê¸ˆ', 'ìê²© ì¡°ê±´', 'ì‹ ì²­ ì‹œê¸°']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [03:20<00:10, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[20/20] ì²˜ë¦¬ ì¤‘: ê³ êµ­ìœ¼ë¡œ ëŒì•„ê°ˆ ë•Œ, ì–¸ì œë¶€í„° ê·€êµ­ë¹„ìš© ë³´í—˜ì„ ì‹ ì²­í•  ìˆ˜ ìˆìœ¼ë©°, ì–´ë–¤ ì„œë¥˜ë¥¼ ì¤€ë¹„í•´ì•¼ í•˜...\n",
      "ì‚¬ìš©í•  í‚¤ì›Œë“œ: ['ê·€êµ­ë¹„ìš© ë³´í—˜', 'ì‹ ì²­ ì‹œê¸°', 'í•„ìš” ì„œë¥˜']\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "Correctness: 0\n",
      "Recall@k: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [03:28<00:00, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ì™„ë£Œ! ===\n",
      "í‰ê·  Correctness: 0.600\n",
      "í‰ê·  Recall@k: 0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ì‹¤í–‰\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë“¤\n",
    "keyword_baseline_results = []\n",
    "keyword_retrieved_doc_ids_list = []\n",
    "\n",
    "# ë©”íŠ¸ë¦­ë³„ ê²°ê³¼ ì €ì¥\n",
    "keyword_correctness_scores = []\n",
    "keyword_recall_at_k_scores = []\n",
    "\n",
    "print(f\"ì´ {len(query_df)}ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•´ í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# ê° ì¿¼ë¦¬ì— ëŒ€í•´ í‰ê°€ ì‹¤í–‰\n",
    "for idx, row in tqdm(query_df.iterrows(), total=len(query_df), desc=\"í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€\"):\n",
    "    query_text = row['translated_4o_mini']\n",
    "    ground_truth_ids = row['ground_truth_id']\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì²˜ë¦¬\n",
    "    try:\n",
    "        keywords_raw = row['keyword_4o_mini']\n",
    "        if isinstance(keywords_raw, str):\n",
    "            keywords = ast.literal_eval(keywords_raw)\n",
    "        else:\n",
    "            keywords = keywords_raw\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{len(query_df)}] ì²˜ë¦¬ ì¤‘: {query_text[:50]}...\")\n",
    "    print(f\"ì‚¬ìš©í•  í‚¤ì›Œë“œ: {keywords}\")\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ê¸°ë°˜ ëª¨ë¸ ì‚¬ìš©\n",
    "    result = get_keyword_model_response_with_docs(query_text, keywords)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    keyword_baseline_results.append(result['answer'])\n",
    "    keyword_retrieved_doc_ids_list.append(result['retrieved_doc_ids'])\n",
    "    \n",
    "    # ëª¨ë“  ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    metrics = calculate_all_metrics(result['retrieved_doc_ids'], ground_truth_ids)\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ ì €ì¥\n",
    "    keyword_correctness_scores.append(metrics['correctness'])\n",
    "    keyword_recall_at_k_scores.append(metrics['recall_at_k'])\n",
    "    \n",
    "    print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_doc_ids'])}\")\n",
    "    print(f\"Correctness: {metrics['correctness']}\")\n",
    "    print(f\"Recall@k: {metrics['recall_at_k']:.3f}\")\n",
    "    \n",
    "    # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ì ì‹œ ëŒ€ê¸°\n",
    "    time.sleep(1)\n",
    "\n",
    "# ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\n=== í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ì™„ë£Œ! ===\")\n",
    "print(f\"í‰ê·  Correctness: {sum(keyword_correctness_scores) / len(keyword_correctness_scores):.3f}\")\n",
    "print(f\"í‰ê·  Recall@k: {sum(keyword_recall_at_k_scores) / len(keyword_recall_at_k_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7237fe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\n",
      "- answer_keyword_hybrid: 20ê°œ\n",
      "- retrieved_doc_ids_keyword: 20ê°œ\n",
      "- correctness_keyword: 20ê°œ\n",
      "- recall_at_k_keyword: 20ê°œ\n",
      "- CSV íŒŒì¼: ../data/keyword_hybrid_evaluation_results_20250916_210503.csv\n",
      "\n",
      "=== í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ê²°ê³¼ ìš”ì•½ ===\n",
      "ì´ ì¿¼ë¦¬ ìˆ˜: 20\n",
      "ì •í™•í•œ ê²€ìƒ‰ ìˆ˜: 12\n",
      "í‰ê·  Correctness: 0.600 (60.0%)\n",
      "í‰ê·  Recall@k: 0.289 (28.9%)\n"
     ]
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ë° ë¹„êµ ë¶„ì„\n",
    "import datetime\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ì— í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€\n",
    "query_df['answer_keyword_hybrid'] = keyword_baseline_results\n",
    "query_df['retrieved_doc_ids_keyword'] = keyword_retrieved_doc_ids_list\n",
    "query_df['correctness_keyword'] = keyword_correctness_scores\n",
    "query_df['recall_at_k_keyword'] = keyword_recall_at_k_scores\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "keyword_evaluation_csv_filename = f\"../data/keyword_hybrid_evaluation_results_{timestamp}.csv\"\n",
    "query_df.to_csv(keyword_evaluation_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\ní‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"- answer_keyword_hybrid: {len(keyword_baseline_results)}ê°œ\")\n",
    "print(f\"- retrieved_doc_ids_keyword: {len(keyword_retrieved_doc_ids_list)}ê°œ\") \n",
    "print(f\"- correctness_keyword: {len(keyword_correctness_scores)}ê°œ\")\n",
    "print(f\"- recall_at_k_keyword: {len(keyword_recall_at_k_scores)}ê°œ\")\n",
    "print(f\"- CSV íŒŒì¼: {keyword_evaluation_csv_filename}\")\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ìƒì„¸ ìš”ì•½\n",
    "total_queries = len(query_df)\n",
    "keyword_correct_retrievals = sum(keyword_correctness_scores)\n",
    "keyword_avg_correctness = keyword_correct_retrievals / total_queries\n",
    "keyword_avg_recall = sum(keyword_recall_at_k_scores) / len(keyword_recall_at_k_scores)\n",
    "\n",
    "print(f\"\\n=== í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "print(f\"ì´ ì¿¼ë¦¬ ìˆ˜: {total_queries}\")\n",
    "print(f\"ì •í™•í•œ ê²€ìƒ‰ ìˆ˜: {keyword_correct_retrievals}\")\n",
    "print(f\"í‰ê·  Correctness: {keyword_avg_correctness:.3f} ({keyword_avg_correctness*100:.1f}%)\")\n",
    "print(f\"í‰ê·  Recall@k: {keyword_avg_recall:.3f} ({keyword_avg_recall*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae14418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/keyword_hybrid_evaluation_results_20250916_205256.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4be5fc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'translated_query', 'ì–¸ì–´', 'ground_truth_id', 'category',\n",
       "       'source', 'ì‘ì„±ì', 'ë¹„ê³ ', 'ì†ŒìŠ¤', 'translated_4o_mini', 'keyword_4o_mini',\n",
       "       'answer_baseline', 'retrieved_doc_ids', 'correctness', 'recall_at_k',\n",
       "       'answer_keyword_hybrid', 'retrieved_doc_ids_keyword',\n",
       "       'correctness_keyword', 'recall_at_k_keyword'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d337df4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correctness_keyword'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e45ffcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2894642857142857)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['recall_at_k_keyword'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4684f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../data/keyword_hybrid_evaluation_results_20250916_210409.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29a81612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['correctness_keyword'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deeeeaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.2894642857142857)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['recall_at_k_keyword'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed2d769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correctness_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ (ì´ì „ í‰ê°€ì—ì„œ)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m baseline_avg_correctness = \u001b[38;5;28msum\u001b[39m(\u001b[43mcorrectness_scores\u001b[49m) / \u001b[38;5;28mlen\u001b[39m(correctness_scores)\n\u001b[32m      8\u001b[39m baseline_avg_recall = \u001b[38;5;28msum\u001b[39m(recall_at_k_scores) / \u001b[38;5;28mlen\u001b[39m(recall_at_k_scores)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ“Š ì„±ëŠ¥ ë¹„êµ:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'correctness_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ vs í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ” ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ ë¶„ì„\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ (ì´ì „ í‰ê°€ì—ì„œ)\n",
    "baseline_avg_correctness = sum(correctness_scores) / len(correctness_scores)\n",
    "baseline_avg_recall = sum(recall_at_k_scores) / len(recall_at_k_scores)\n",
    "\n",
    "print(f\"\\nğŸ“Š ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(f\"{'ë©”íŠ¸ë¦­':<20} {'ë²¡í„° ê²€ìƒ‰':<15} {'í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ':<20} {'ê°œì„ ë„':<15}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Correctness':<20} {baseline_avg_correctness:.3f} ({baseline_avg_correctness*100:.1f}%){'':<5} {keyword_avg_correctness:.3f} ({keyword_avg_correctness*100:.1f}%){'':<5} {((keyword_avg_correctness - baseline_avg_correctness) / baseline_avg_correctness * 100):+.1f}%\")\n",
    "print(f\"{'Recall@k':<20} {baseline_avg_recall:.3f} ({baseline_avg_recall*100:.1f}%){'':<5} {keyword_avg_recall:.3f} ({keyword_avg_recall*100:.1f}%){'':<5} {((keyword_avg_recall - baseline_avg_recall) / baseline_avg_recall * 100):+.1f}%\")\n",
    "\n",
    "# ê°œì„ ëœ ì¿¼ë¦¬ ìˆ˜ ê³„ì‚°\n",
    "correctness_improved = sum(1 for i in range(len(query_df)) if keyword_correctness_scores[i] > correctness_scores[i])\n",
    "recall_improved = sum(1 for i in range(len(query_df)) if keyword_recall_at_k_scores[i] > recall_at_k_scores[i])\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ê°œì„  í†µê³„:\")\n",
    "print(f\"Correctness ê°œì„ ëœ ì¿¼ë¦¬: {correctness_improved}/{len(query_df)}ê°œ ({correctness_improved/len(query_df)*100:.1f}%)\")\n",
    "print(f\"Recall@k ê°œì„ ëœ ì¿¼ë¦¬: {recall_improved}/{len(query_df)}ê°œ ({recall_improved/len(query_df)*100:.1f}%)\")\n",
    "\n",
    "# ìƒì„¸ ë¹„êµë¥¼ ìœ„í•œ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(f\"\\nğŸ“‹ ìƒì„¸ ë¹„êµ ìƒ˜í”Œ (ìƒìœ„ 5ê°œ):\")\n",
    "comparison_df = query_df[['query', 'correctness', 'recall_at_k', 'correctness_keyword', 'recall_at_k_keyword']].head(5)\n",
    "\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"\\n[ìƒ˜í”Œ {idx+1}]\")\n",
    "    print(f\"ì¿¼ë¦¬: {row['query'][:60]}...\")\n",
    "    print(f\"ë²¡í„° ê²€ìƒ‰ - Correctness: {row['correctness']}, Recall@k: {row['recall_at_k']:.3f}\")\n",
    "    print(f\"í‚¤ì›Œë“œ í•˜ì´ë¸Œë¦¬ë“œ - Correctness: {row['correctness_keyword']}, Recall@k: {row['recall_at_k_keyword']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf980b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
