{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking 평가\n",
    "\n",
    "- Cross-encoder 기반 reranker 모듈을 도입하여 성능 향상 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, builtins, logging\n",
    "\n",
    "# repo 루트 기준으로 utils 임포트 가능하도록 경로 추가\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils.logging_setup import setup_logging\n",
    "\n",
    "# UTF-8 파일 핸들러로 로그 초기화 (logs/{timestamp}.log)\n",
    "# print를 직접 로거로 보낼 것이므로 redirect_prints는 False\n",
    "setup_logging(force=True, redirect_prints=False)\n",
    "\n",
    "# print를 로거로 보내되, 기존 콘솔 출력도 유지\n",
    "_original_print = builtins.print\n",
    "\n",
    "def print(*args, **kwargs):  # noqa: A001 (shadow builtins)\n",
    "    message = \" \".join(str(a) for a in args)\n",
    "    logging.info(message)\n",
    "    try:\n",
    "        _original_print(*args, **kwargs)\n",
    "    except Exception:\n",
    "        # 콘솔 출력 실패 시에도 로깅은 유지\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API 설정 및 라이브러리 import\n",
    "from openai import OpenAI\n",
    "import os, sys\n",
    "from typing import List, Dict\n",
    "import dotenv\n",
    "import sys\n",
    "\n",
    "# 프로젝트 루트 디렉토리를 Python 경로에 추가\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 설정\n",
    "\n",
    "# API 키 설정 (환경변수에서 가져오기)\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # 환경변수에 API 키를 설정해주세요\n",
    ")\n",
    "\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",          # JSON 스키마 강제 모드\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"translate_result\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"translated\": { \"type\": \"string\" },\n",
    "                \"mongo_query\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"minItems\": 1,\n",
    "                    # 각 stage는 자유형 객체로 허용(예: {\"$search\": {...}}, {\"$project\": {...}})\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"additionalProperties\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"translated\", \"mongo_query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    },\n",
    "    # 스키마를 더 엄격히 따르게 함(모델이 스키마 밖 형식을 내보내지 않도록)\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "def chat(\n",
    "    messages: List[Dict[str, str]], \n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    response_format: dict = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    OpenAI GPT-4o-mini API를 사용하여 채팅 완성을 수행합니다.\n",
    "    \n",
    "    Args:\n",
    "        messages: 대화 메시지 리스트 [{\"role\": \"user\", \"content\": \"메시지\"}]\n",
    "        model: 사용할 모델명 (기본값: gpt-4o-mini)\n",
    "        **kwargs: OpenAI API 매개변수들\n",
    "            - temperature: 창의성 조절 (0.0-2.0, 기본값: 0.7)\n",
    "            - max_tokens: 최대 토큰 수 (기본값: 1000)\n",
    "            - top_p: 확률 임계값 (기본값: 0.95)\n",
    "            - frequency_penalty: 빈도 페널티 (기본값: 0.0)\n",
    "            - presence_penalty: 존재 페널티 (기본값: 0.0)\n",
    "            - stream: 스트리밍 여부 (기본값: False)\n",
    "            - 기타 OpenAI API가 지원하는 모든 매개변수\n",
    "        \n",
    "    Returns:\n",
    "        GPT 응답 텍스트\n",
    "    \"\"\"\n",
    "    # 기본값 설정\n",
    "    default_params = {\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"presence_penalty\": 0.0\n",
    "    }\n",
    "    \n",
    "    # 기본값과 사용자 입력 병합\n",
    "    params = {**default_params, **kwargs}\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format=response_format,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"API 호출 중 오류 발생: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB 연결 테스트\n",
    "import json\n",
    "import os\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MongoDB 연결 테스트 시작\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 설정 파일 로드\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# MongoDB 클라이언트 연결\n",
    "mongodb_client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "print(\"🔗 MongoDB 클라이언트 연결 완료\")\n",
    "\n",
    "try:\n",
    "    mongodb_client.admin.command('ping')\n",
    "    print(\"✅ MongoDB 연결 성공!\")\n",
    "    \n",
    "    current_db = mongodb_client[config['path']['db_name']]\n",
    "    target_collection = current_db[config['path']['collection_name']]\n",
    "    \n",
    "    print(f\"🎯 현재 데이터베이스: {config['path']['db_name']}\")\n",
    "    print(f\"🎯 타겟 컬렉션: {config['path']['collection_name']}\")\n",
    "    \n",
    "    # 컬렉션 통계 정보\n",
    "    stats = current_db.command(\"collStats\", config['path']['collection_name'])\n",
    "    print(f\"📈 문서 개수: {stats['count']:,}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"✅ MongoDB 연결 테스트 완료!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 오류: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험 2 파이프라인 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# 프로젝트 루트 디렉토리를 Python 경로에 추가\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "query_df = pd.read_csv(\"../data/helloworld_test_query_with_translation_query_20250930_191253.csv\")\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reranking 모델 설정\n",
    "from Azure.reranking_model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "# Reranking 모델 인스턴스 생성\n",
    "reranking_chat_model = ChatModel(config)\n",
    "\n",
    "print(\"Reranking 기반 하이브리드 검색 모델 설정 완료\")\n",
    "print(f\"Reranker 모델: {config['reranker_config']['model']}\")\n",
    "print(f\"후보 문서 수: {config['reranker_config']['numCandidates']}\")\n",
    "print(f\"최종 반환 문서 수: {config['chat_config']['top_k']}\")\n",
    "\n",
    "print(\"쿼리 기반 하이브리드 검색 모델 설정 완료\")\n",
    "\n",
    "# 키워드 기반 검색 함수\n",
    "def get_query_model_response_with_docs(query_text, mongo_query):\n",
    "    \"\"\"\n",
    "    키워드 기반 하이브리드 검색 모델로부터 답변을 생성하고 검색된 문서들의 인덱스를 반환\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 빈 대화 히스토리로 시작\n",
    "        conversation_history = []\n",
    "        \n",
    "        # 키워드 기반 모델 답변 생성\n",
    "        response = reranking_chat_model.generate_ai_response(\n",
    "            conversation_history, \n",
    "            query_text, \n",
    "            target_collection, \n",
    "            mongo_query=mongo_query\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response[\"answer\"],\n",
    "            \"retrieved_doc_ids\": response[\"retrieved_doc_ids\"],\n",
    "            \"retrieved_docs\": response[\"retrieved_docs\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"\",\n",
    "            \"retrieved_doc_ids\": [],\n",
    "            \"retrieved_docs\": []\n",
    "        }\n",
    "\n",
    "print(\"쿼리 기반 검색 함수 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Correctness 계산 함수\n",
    "def calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids):\n",
    "    \"\"\"\n",
    "    검색된 문서 ID들과 ground truth ID들을 비교하여 correctness 계산\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0\n",
    "    \n",
    "    # ground_truth_ids가 문자열 리스트인 경우 처리\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            # 문자열을 리스트로 변환 (예: \"['id1', 'id2']\" -> ['id1', 'id2'])\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # 검색된 문서 중 하나라도 ground truth에 있으면 1, 아니면 0\n",
    "    for doc_id in retrieved_doc_ids:\n",
    "        if doc_id in ground_truth_list:\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "print(\"Retrieval Correctness 계산 함수 정의 완료\")\n",
    "\n",
    "# 확장된 Retrieval 메트릭 계산 함수들\n",
    "def calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    Recall@k 계산: 검색된 문서 중 관련 문서의 비율\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0.0\n",
    "    \n",
    "    # ground_truth_ids가 문자열 리스트인 경우 처리\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # k가 지정되지 않으면 검색된 문서 수만큼 사용\n",
    "    if k is None:\n",
    "        k = len(retrieved_doc_ids)\n",
    "    \n",
    "    # 상위 k개 문서만 고려\n",
    "    top_k_retrieved = retrieved_doc_ids[:k]\n",
    "    \n",
    "    # 관련 문서 수 계산\n",
    "    relevant_retrieved = sum(1 for doc_id in top_k_retrieved if doc_id in ground_truth_list)\n",
    "    \n",
    "    # Recall = 관련 문서 수 / 전체 관련 문서 수\n",
    "    if len(ground_truth_list) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return relevant_retrieved / len(ground_truth_list)\n",
    "\n",
    "\n",
    "def calculate_all_metrics(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    모든 메트릭을 한 번에 계산\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"correctness\": calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids),\n",
    "        \"recall_at_k\": calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k)\n",
    "    }\n",
    "\n",
    "print(\"확장된 Retrieval 메트릭 계산 함수들 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안전한 mongo_query 파싱 및 평가 루프 대체\n",
    "import json, ast, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_mongo_query(query_raw):\n",
    "    # 이미 리스트[dict]\n",
    "    if isinstance(query_raw, list):\n",
    "        return query_raw\n",
    "    # 문자열이면 ast 우선 → json → 마지막으로 단순치환 후 json\n",
    "    if isinstance(query_raw, str):\n",
    "        for parser in (ast.literal_eval, json.loads):\n",
    "            try:\n",
    "                return parser(query_raw)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # 단순 따옴표 치환 시도 (가능한 경우에만)\n",
    "        try:\n",
    "            sanitized = query_raw.replace(\"'\", '\"')\n",
    "            return json.loads(sanitized)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    raise ValueError(\"Unsupported mongo_query type: {}\".format(type(query_raw)))\n",
    "\n",
    "# 평가 실행 (기존 변수들 재사용)\n",
    "baseline_results = []\n",
    "retrieved_doc_ids_list = []\n",
    "correctness_scores = []\n",
    "recall_at_k_scores = []\n",
    "\n",
    "print(f\"총 {len(query_df)}개의 쿼리에 대해 쿼리 기반 하이브리드 검색 평가를 시작합니다...\")\n",
    "\n",
    "for idx, row in tqdm(query_df.iterrows(), total=len(query_df), desc=\"쿼리 하이브리드 검색 평가\"): \n",
    "    query_text = row['translated_4o_mini']\n",
    "    ground_truth_ids = row['ground_truth_id']\n",
    "\n",
    "    try:\n",
    "        mongo_query = parse_mongo_query(row['mongo_query_4o_mini'])\n",
    "    except Exception as e:\n",
    "        print(f\"파싱 실패로 해당 샘플 건너뜀: {e}\")\n",
    "        baseline_results.append(\"\")\n",
    "        retrieved_doc_ids_list.append([])\n",
    "        correctness_scores.append(0)\n",
    "        recall_at_k_scores.append(0.0)\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n[{idx+1}/{len(query_df)}] 처리 중: {query_text[:50]}...\")\n",
    "    print(f\"사용할 쿼리: {mongo_query}\")\n",
    "\n",
    "    result = get_query_model_response_with_docs(query_text, mongo_query)\n",
    "\n",
    "    baseline_results.append(result['answer'])\n",
    "    retrieved_doc_ids_list.append(result['retrieved_doc_ids'])\n",
    "\n",
    "    metrics = calculate_all_metrics(result['retrieved_doc_ids'], ground_truth_ids)\n",
    "    correctness_scores.append(metrics['correctness'])\n",
    "    recall_at_k_scores.append(metrics['recall_at_k'])\n",
    "\n",
    "    print(f\"검색된 문서 수: {len(result['retrieved_doc_ids'])}\")\n",
    "    print(f\"Correctness: {metrics['correctness']}\")\n",
    "    print(f\"Recall@k: {metrics['recall_at_k']:.3f}\")\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\n=== 키워드 기반 하이브리드 검색 평가 완료! ===\")\n",
    "print(f\"평균 Correctness: {sum(correctness_scores) / len(correctness_scores):.3f}\")\n",
    "print(f\"평균 Recall@k: {sum(recall_at_k_scores) / len(recall_at_k_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 기반 검색 결과 저장 및 비교 분석\n",
    "import datetime\n",
    "\n",
    "# 데이터프레임에 키워드 기반 검색 결과 추가\n",
    "query_df['answer'] = baseline_results\n",
    "query_df['retrieved_doc_ids'] = retrieved_doc_ids_list\n",
    "query_df['correctness'] = correctness_scores\n",
    "query_df['recall_at_k'] = recall_at_k_scores\n",
    "\n",
    "# 결과 저장\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "evaluation_csv_filename = f\"../data/evaluation_results_{timestamp}.csv\"\n",
    "query_df.to_csv(evaluation_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\n키워드 기반 검색 결과 저장 완료:\")\n",
    "print(f\"- answer: {len(baseline_results)}개\")\n",
    "print(f\"- retrieved_doc_ids: {len(retrieved_doc_ids_list)}개\") \n",
    "print(f\"- correctness: {len(correctness_scores)}개\")\n",
    "print(f\"- recall_at_k: {len(recall_at_k_scores)}개\")\n",
    "print(f\"- CSV 파일: {evaluation_csv_filename}\")\n",
    "\n",
    "# 평가 결과 상세 요약\n",
    "total_queries = len(query_df)\n",
    "correct_retrievals = sum(correctness_scores)\n",
    "avg_correctness = correct_retrievals / total_queries\n",
    "avg_recall = sum(recall_at_k_scores) / len(recall_at_k_scores)\n",
    "\n",
    "print(f\"\\n=== 키워드 기반 하이브리드 검색 평가 결과 요약 ===\")\n",
    "print(f\"총 쿼리 수: {total_queries}\")\n",
    "print(f\"정확한 검색 수: {correct_retrievals}\")\n",
    "print(f\"평균 Correctness: {avg_correctness:.3f} ({avg_correctness*100:.1f}%)\")\n",
    "print(f\"평균 Recall@k: {avg_recall:.3f} ({avg_recall*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장 및 비교 분석\n",
    "import datetime\n",
    "\n",
    "# 결과 저장\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "reranking_csv_filename = f\"../data/reranking_evaluation_results_{timestamp}.csv\"\n",
    "query_df.to_csv(reranking_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nReranking 평가 결과 저장 완료: {reranking_csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helloworld-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
