{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking í‰ê°€\n",
    "\n",
    "- Cross-encoder ê¸°ë°˜ reranker ëª¨ë“ˆì„ ë„ì…í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, builtins, logging\n",
    "\n",
    "# repo ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ utils ì„í¬íŠ¸ ê°€ëŠ¥í•˜ë„ë¡ ê²½ë¡œ ì¶”ê°€\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils.logging_setup import setup_logging\n",
    "\n",
    "# UTF-8 íŒŒì¼ í•¸ë“¤ëŸ¬ë¡œ ë¡œê·¸ ì´ˆê¸°í™” (logs/{timestamp}.log)\n",
    "# printë¥¼ ì§ì ‘ ë¡œê±°ë¡œ ë³´ë‚¼ ê²ƒì´ë¯€ë¡œ redirect_printsëŠ” False\n",
    "setup_logging(force=True, redirect_prints=False)\n",
    "\n",
    "# printë¥¼ ë¡œê±°ë¡œ ë³´ë‚´ë˜, ê¸°ì¡´ ì½˜ì†” ì¶œë ¥ë„ ìœ ì§€\n",
    "_original_print = builtins.print\n",
    "\n",
    "def print(*args, **kwargs):  # noqa: A001 (shadow builtins)\n",
    "    message = \" \".join(str(a) for a in args)\n",
    "    logging.info(message)\n",
    "    try:\n",
    "        _original_print(*args, **kwargs)\n",
    "    except Exception:\n",
    "        # ì½˜ì†” ì¶œë ¥ ì‹¤íŒ¨ ì‹œì—ë„ ë¡œê¹…ì€ ìœ ì§€\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "from openai import OpenAI\n",
    "import os, sys\n",
    "from typing import List, Dict\n",
    "import dotenv\n",
    "import sys\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai ì„¤ì •\n",
    "\n",
    "# API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # í™˜ê²½ë³€ìˆ˜ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”\n",
    ")\n",
    "\n",
    "\n",
    "response_format = {\n",
    "    \"type\": \"json_schema\",          # JSON ìŠ¤í‚¤ë§ˆ ê°•ì œ ëª¨ë“œ\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"translate_result\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"translated\": { \"type\": \"string\" },\n",
    "                \"mongo_query\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"minItems\": 1,\n",
    "                    # ê° stageëŠ” ììœ í˜• ê°ì²´ë¡œ í—ˆìš©(ì˜ˆ: {\"$search\": {...}}, {\"$project\": {...}})\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"additionalProperties\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"translated\", \"mongo_query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    },\n",
    "    # ìŠ¤í‚¤ë§ˆë¥¼ ë” ì—„ê²©íˆ ë”°ë¥´ê²Œ í•¨(ëª¨ë¸ì´ ìŠ¤í‚¤ë§ˆ ë°– í˜•ì‹ì„ ë‚´ë³´ë‚´ì§€ ì•Šë„ë¡)\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "def chat(\n",
    "    messages: List[Dict[str, str]], \n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    response_format: dict = None,\n",
    "    **kwargs\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    OpenAI GPT-4o-mini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì™„ì„±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ [{\"role\": \"user\", \"content\": \"ë©”ì‹œì§€\"}]\n",
    "        model: ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’: gpt-4o-mini)\n",
    "        **kwargs: OpenAI API ë§¤ê°œë³€ìˆ˜ë“¤\n",
    "            - temperature: ì°½ì˜ì„± ì¡°ì ˆ (0.0-2.0, ê¸°ë³¸ê°’: 0.7)\n",
    "            - max_tokens: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 1000)\n",
    "            - top_p: í™•ë¥  ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.95)\n",
    "            - frequency_penalty: ë¹ˆë„ í˜ë„í‹° (ê¸°ë³¸ê°’: 0.0)\n",
    "            - presence_penalty: ì¡´ì¬ í˜ë„í‹° (ê¸°ë³¸ê°’: 0.0)\n",
    "            - stream: ìŠ¤íŠ¸ë¦¬ë° ì—¬ë¶€ (ê¸°ë³¸ê°’: False)\n",
    "            - ê¸°íƒ€ OpenAI APIê°€ ì§€ì›í•˜ëŠ” ëª¨ë“  ë§¤ê°œë³€ìˆ˜\n",
    "        \n",
    "    Returns:\n",
    "        GPT ì‘ë‹µ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "    default_params = {\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"presence_penalty\": 0.0\n",
    "    }\n",
    "    \n",
    "    # ê¸°ë³¸ê°’ê³¼ ì‚¬ìš©ì ì…ë ¥ ë³‘í•©\n",
    "    params = {**default_params, **kwargs}\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            response_format=response_format,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "import json\n",
    "import os\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²°\n",
    "mongodb_client = MongoClient(os.getenv(\"MONGODB_URI\"))\n",
    "print(\"ğŸ”— MongoDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì™„ë£Œ\")\n",
    "\n",
    "try:\n",
    "    mongodb_client.admin.command('ping')\n",
    "    print(\"âœ… MongoDB ì—°ê²° ì„±ê³µ!\")\n",
    "    \n",
    "    current_db = mongodb_client[config['path']['db_name']]\n",
    "    target_collection = current_db[config['path']['collection_name']]\n",
    "    \n",
    "    print(f\"ğŸ¯ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤: {config['path']['db_name']}\")\n",
    "    print(f\"ğŸ¯ íƒ€ê²Ÿ ì»¬ë ‰ì…˜: {config['path']['collection_name']}\")\n",
    "    \n",
    "    # ì»¬ë ‰ì…˜ í†µê³„ ì •ë³´\n",
    "    stats = current_db.command(\"collStats\", config['path']['collection_name'])\n",
    "    print(f\"ğŸ“ˆ ë¬¸ì„œ ê°œìˆ˜: {stats['count']:,}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"âœ… MongoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤í—˜ 2 íŒŒì´í”„ë¼ì¸ ê¸°ë°˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "query_df = pd.read_csv(\"../data/helloworld_test_query_with_translation_query_20250930_191253.csv\")\n",
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reranking ëª¨ë¸ ì„¤ì •\n",
    "from Azure.reranking_model import ChatModel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "with open('../configs/config.json', 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "# Reranking ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "reranking_chat_model = ChatModel(config)\n",
    "\n",
    "print(\"Reranking ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"Reranker ëª¨ë¸: {config['reranker_config']['model']}\")\n",
    "print(f\"í›„ë³´ ë¬¸ì„œ ìˆ˜: {config['reranker_config']['numCandidates']}\")\n",
    "print(f\"ìµœì¢… ë°˜í™˜ ë¬¸ì„œ ìˆ˜: {config['chat_config']['top_k']}\")\n",
    "\n",
    "print(\"ì¿¼ë¦¬ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜\n",
    "def get_query_model_response_with_docs(query_text, mongo_query):\n",
    "    \"\"\"\n",
    "    í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë¸ë¡œë¶€í„° ë‹µë³€ì„ ìƒì„±í•˜ê³  ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ë¹ˆ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¡œ ì‹œì‘\n",
    "        conversation_history = []\n",
    "        \n",
    "        # í‚¤ì›Œë“œ ê¸°ë°˜ ëª¨ë¸ ë‹µë³€ ìƒì„±\n",
    "        response = reranking_chat_model.generate_ai_response(\n",
    "            conversation_history, \n",
    "            query_text, \n",
    "            target_collection, \n",
    "            mongo_query=mongo_query\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response[\"answer\"],\n",
    "            \"retrieved_doc_ids\": response[\"retrieved_doc_ids\"],\n",
    "            \"retrieved_docs\": response[\"retrieved_docs\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"\",\n",
    "            \"retrieved_doc_ids\": [],\n",
    "            \"retrieved_docs\": []\n",
    "        }\n",
    "\n",
    "print(\"ì¿¼ë¦¬ ê¸°ë°˜ ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval Correctness ê³„ì‚° í•¨ìˆ˜\n",
    "def calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰ëœ ë¬¸ì„œ IDë“¤ê³¼ ground truth IDë“¤ì„ ë¹„êµí•˜ì—¬ correctness ê³„ì‚°\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0\n",
    "    \n",
    "    # ground_truth_idsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì˜ˆ: \"['id1', 'id2']\" -> ['id1', 'id2'])\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ í•˜ë‚˜ë¼ë„ ground truthì— ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "    for doc_id in retrieved_doc_ids:\n",
    "        if doc_id in ground_truth_list:\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "\n",
    "print(\"Retrieval Correctness ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "\n",
    "# í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤\n",
    "def calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    Recall@k ê³„ì‚°: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ê´€ë ¨ ë¬¸ì„œì˜ ë¹„ìœ¨\n",
    "    \"\"\"\n",
    "    if not retrieved_doc_ids or not ground_truth_ids:\n",
    "        return 0.0\n",
    "    \n",
    "    # ground_truth_idsê°€ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬\n",
    "    if isinstance(ground_truth_ids, str):\n",
    "        try:\n",
    "            import ast\n",
    "            ground_truth_list = ast.literal_eval(ground_truth_ids)\n",
    "        except:\n",
    "            ground_truth_list = [ground_truth_ids]\n",
    "    else:\n",
    "        ground_truth_list = ground_truth_ids\n",
    "    \n",
    "    # kê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜ë§Œí¼ ì‚¬ìš©\n",
    "    if k is None:\n",
    "        k = len(retrieved_doc_ids)\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ë¬¸ì„œë§Œ ê³ ë ¤\n",
    "    top_k_retrieved = retrieved_doc_ids[:k]\n",
    "    \n",
    "    # ê´€ë ¨ ë¬¸ì„œ ìˆ˜ ê³„ì‚°\n",
    "    relevant_retrieved = sum(1 for doc_id in top_k_retrieved if doc_id in ground_truth_list)\n",
    "    \n",
    "    # Recall = ê´€ë ¨ ë¬¸ì„œ ìˆ˜ / ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ìˆ˜\n",
    "    if len(ground_truth_list) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return relevant_retrieved / len(ground_truth_list)\n",
    "\n",
    "\n",
    "def calculate_all_metrics(retrieved_doc_ids, ground_truth_ids, k=None):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ë©”íŠ¸ë¦­ì„ í•œ ë²ˆì— ê³„ì‚°\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"correctness\": calculate_retrieval_correctness(retrieved_doc_ids, ground_truth_ids),\n",
    "        \"recall_at_k\": calculate_recall_at_k(retrieved_doc_ids, ground_truth_ids, k)\n",
    "    }\n",
    "\n",
    "print(\"í™•ì¥ëœ Retrieval ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•ˆì „í•œ mongo_query íŒŒì‹± ë° í‰ê°€ ë£¨í”„ ëŒ€ì²´\n",
    "import json, ast, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_mongo_query(query_raw):\n",
    "    # ì´ë¯¸ ë¦¬ìŠ¤íŠ¸[dict]\n",
    "    if isinstance(query_raw, list):\n",
    "        return query_raw\n",
    "    # ë¬¸ìì—´ì´ë©´ ast ìš°ì„  â†’ json â†’ ë§ˆì§€ë§‰ìœ¼ë¡œ ë‹¨ìˆœì¹˜í™˜ í›„ json\n",
    "    if isinstance(query_raw, str):\n",
    "        for parser in (ast.literal_eval, json.loads):\n",
    "            try:\n",
    "                return parser(query_raw)\n",
    "            except Exception:\n",
    "                pass\n",
    "        # ë‹¨ìˆœ ë”°ì˜´í‘œ ì¹˜í™˜ ì‹œë„ (ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)\n",
    "        try:\n",
    "            sanitized = query_raw.replace(\"'\", '\"')\n",
    "            return json.loads(sanitized)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    raise ValueError(\"Unsupported mongo_query type: {}\".format(type(query_raw)))\n",
    "\n",
    "# í‰ê°€ ì‹¤í–‰ (ê¸°ì¡´ ë³€ìˆ˜ë“¤ ì¬ì‚¬ìš©)\n",
    "baseline_results = []\n",
    "retrieved_doc_ids_list = []\n",
    "correctness_scores = []\n",
    "recall_at_k_scores = []\n",
    "\n",
    "print(f\"ì´ {len(query_df)}ê°œì˜ ì¿¼ë¦¬ì— ëŒ€í•´ ì¿¼ë¦¬ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "for idx, row in tqdm(query_df.iterrows(), total=len(query_df), desc=\"ì¿¼ë¦¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€\"): \n",
    "    query_text = row['translated_4o_mini']\n",
    "    ground_truth_ids = row['ground_truth_id']\n",
    "\n",
    "    try:\n",
    "        mongo_query = parse_mongo_query(row['mongo_query_4o_mini'])\n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì‹± ì‹¤íŒ¨ë¡œ í•´ë‹¹ ìƒ˜í”Œ ê±´ë„ˆëœ€: {e}\")\n",
    "        baseline_results.append(\"\")\n",
    "        retrieved_doc_ids_list.append([])\n",
    "        correctness_scores.append(0)\n",
    "        recall_at_k_scores.append(0.0)\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n[{idx+1}/{len(query_df)}] ì²˜ë¦¬ ì¤‘: {query_text[:50]}...\")\n",
    "    print(f\"ì‚¬ìš©í•  ì¿¼ë¦¬: {mongo_query}\")\n",
    "\n",
    "    result = get_query_model_response_with_docs(query_text, mongo_query)\n",
    "\n",
    "    baseline_results.append(result['answer'])\n",
    "    retrieved_doc_ids_list.append(result['retrieved_doc_ids'])\n",
    "\n",
    "    metrics = calculate_all_metrics(result['retrieved_doc_ids'], ground_truth_ids)\n",
    "    correctness_scores.append(metrics['correctness'])\n",
    "    recall_at_k_scores.append(metrics['recall_at_k'])\n",
    "\n",
    "    print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(result['retrieved_doc_ids'])}\")\n",
    "    print(f\"Correctness: {metrics['correctness']}\")\n",
    "    print(f\"Recall@k: {metrics['recall_at_k']:.3f}\")\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\n=== í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ì™„ë£Œ! ===\")\n",
    "print(f\"í‰ê·  Correctness: {sum(correctness_scores) / len(correctness_scores):.3f}\")\n",
    "print(f\"í‰ê·  Recall@k: {sum(recall_at_k_scores) / len(recall_at_k_scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ë° ë¹„êµ ë¶„ì„\n",
    "import datetime\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ì— í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€\n",
    "query_df['answer'] = baseline_results\n",
    "query_df['retrieved_doc_ids'] = retrieved_doc_ids_list\n",
    "query_df['correctness'] = correctness_scores\n",
    "query_df['recall_at_k'] = recall_at_k_scores\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "evaluation_csv_filename = f\"../data/evaluation_results_{timestamp}.csv\"\n",
    "query_df.to_csv(evaluation_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\ní‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"- answer: {len(baseline_results)}ê°œ\")\n",
    "print(f\"- retrieved_doc_ids: {len(retrieved_doc_ids_list)}ê°œ\") \n",
    "print(f\"- correctness: {len(correctness_scores)}ê°œ\")\n",
    "print(f\"- recall_at_k: {len(recall_at_k_scores)}ê°œ\")\n",
    "print(f\"- CSV íŒŒì¼: {evaluation_csv_filename}\")\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ìƒì„¸ ìš”ì•½\n",
    "total_queries = len(query_df)\n",
    "correct_retrievals = sum(correctness_scores)\n",
    "avg_correctness = correct_retrievals / total_queries\n",
    "avg_recall = sum(recall_at_k_scores) / len(recall_at_k_scores)\n",
    "\n",
    "print(f\"\\n=== í‚¤ì›Œë“œ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‰ê°€ ê²°ê³¼ ìš”ì•½ ===\")\n",
    "print(f\"ì´ ì¿¼ë¦¬ ìˆ˜: {total_queries}\")\n",
    "print(f\"ì •í™•í•œ ê²€ìƒ‰ ìˆ˜: {correct_retrievals}\")\n",
    "print(f\"í‰ê·  Correctness: {avg_correctness:.3f} ({avg_correctness*100:.1f}%)\")\n",
    "print(f\"í‰ê·  Recall@k: {avg_recall:.3f} ({avg_recall*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥ ë° ë¹„êµ ë¶„ì„\n",
    "import datetime\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "reranking_csv_filename = f\"../data/reranking_evaluation_results_{timestamp}.csv\"\n",
    "query_df.to_csv(reranking_csv_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nReranking í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {reranking_csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helloworld-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
